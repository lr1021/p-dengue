{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059ec4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from rasterstats import zonal_stats\n",
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "from rasterio.enums import Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "from rasterio.features import rasterize\n",
    "from data_utils import best_res_align, align_r1_to_r2\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e1c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laptop folder\n",
    "folder = \"../../_data/p-dengue/\"\n",
    "valid_admin2 = pd.read_csv(os.path.join(folder, 'valid_admin/valid_admin2.csv'), header=None)[0].tolist()\n",
    "valid_admin1 = pd.read_csv(os.path.join(folder, 'valid_admin/valid_admin1.csv'), header=None)[0].tolist()\n",
    "valid_admin2.sort()\n",
    "valid_admin1.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb71c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapefile crs: EPSG:4326\n",
      "raster_pop crs: EPSG:4326\n",
      "raster_urbanisation crs: ESRI:54009\n",
      "raster_urbanisation crs projected to: EPSG:4326\n",
      "raster_surveillance crs: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "#### shape data\n",
    "admin1_shp = gpd.read_file(os.path.join(folder,\"shapefiles/admin1/admin1_38.shp\"))\n",
    "admin2_shp = gpd.read_file(os.path.join(folder,\"shapefiles/admin2/admin2_38.shp\"))\n",
    "\n",
    "admin1_shp = (admin1_shp[admin1_shp[\"admin1\"].isin(valid_admin1)].sort_values(\"admin1\").reset_index(drop=True))\n",
    "admin2_shp = (admin2_shp[admin2_shp[\"admin2\"].isin(valid_admin2)].sort_values(\"admin2\").reset_index(drop=True))\n",
    "\n",
    "print(f'shapefile crs: {admin1_shp.crs}')\n",
    "\n",
    "#### Population raster\n",
    "raster_pop = {year :  rxr.open_rasterio(os.path.join(folder, f'raster_pop/landscan-global-{year}.tif'), masked=True) for year in range(2015,2025)}\n",
    "print(f'raster_pop crs: {raster_pop[2015].rio.crs}')\n",
    "\n",
    "#### Urban raster (GHSL GHS-SMOD)\n",
    "raster_urbanisation = rxr.open_rasterio(os.path.join(folder, 'raster_urbanisation/GHS_SMOD_E2020_GLOBE_R2023A_54009_1000_V2_0.tif'), masked=True)\n",
    "\n",
    "raster_urbanisation_binary = raster_urbanisation.copy()\n",
    "urban_classes = [21, 22, 23, 30]\n",
    "raster_urbanisation_binary = raster_urbanisation_binary.where(~raster_urbanisation_binary.isin(urban_classes), other=1)\n",
    "rural_classes = [10, 11, 12, 13]\n",
    "raster_urbanisation_binary = raster_urbanisation_binary.where(~raster_urbanisation_binary.isin(rural_classes), other=0)\n",
    "raster_urbanisation_binary = raster_urbanisation_binary.where((raster_urbanisation_binary == 0) | (raster_urbanisation_binary == 1))\n",
    "print(f'raster_urbanisation crs: {raster_urbanisation.rio.crs}')\n",
    "raster_urbanisation = raster_urbanisation.rio.reproject(admin1_shp.crs)\n",
    "raster_urbanisation_binary = raster_urbanisation_binary.rio.reproject(admin1_shp.crs)\n",
    "print(f'raster_urbanisation crs projected to: {raster_urbanisation.rio.crs}')\n",
    "\n",
    "#### Surveillance raster (Ahyoung Lim et al. Nature Medicine)\n",
    "raster_surveillance = rxr.open_rasterio(os.path.join(folder, 'raster_surveillance/Surveillance_map_wmean.tif'), masked=True)\n",
    "# EPSG:4326\n",
    "raster_surveillance = raster_surveillance.rio.write_crs(\"EPSG:4326\")\n",
    "print(f'raster_surveillance crs: {raster_surveillance.rio.crs}')\n",
    "\n",
    "#### Climate data rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173090aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = admin1_shp.union_all()\n",
    "merged_buffered = gpd.GeoDataFrame(geometry=[merged], crs=admin1_shp.crs)\n",
    "merged_buffered[\"geometry\"] = (merged_buffered.to_crs(\"EPSG:3857\").buffer(20_000).to_crs(\"EPSG:4326\"))\n",
    "region_bounds_buffered = merged_buffered.bounds.iloc[0, :].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41566459",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_crop_alignment = raster_pop[2015].squeeze().rio.clip_box(minx=region_bounds_buffered[0], miny=region_bounds_buffered[1],\n",
    "                                                   maxx=region_bounds_buffered[2], maxy=region_bounds_buffered[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5d18a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### admin_year_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a2c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_records = []\n",
    "admin2_records = []\n",
    "\n",
    "for year in range(2015,2025):\n",
    "    pop_crop = raster_pop[year].squeeze().rio.clip_box(minx=region_bounds_buffered[0], miny=region_bounds_buffered[1],\n",
    "                                                   maxx=region_bounds_buffered[2], maxy=region_bounds_buffered[3])\n",
    "    admin1_pop_stats = zonal_stats(\n",
    "        vectors=admin1_shp,\n",
    "        raster=pop_crop.values,\n",
    "        affine=pop_crop.rio.transform(),\n",
    "        stats=[\"sum\"],\n",
    "        nodata=pop_crop.rio.nodata,\n",
    "        all_touched=True)\n",
    "    \n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        admin1_records.append({\n",
    "            \"admin1\": row.admin1,\n",
    "            \"year\": year,\n",
    "            \"population\": admin1_pop_stats[i][\"sum\"]\n",
    "        })\n",
    "\n",
    "    admin2_pop_stats = zonal_stats(\n",
    "        vectors=admin2_shp,\n",
    "        raster=pop_crop.values,\n",
    "        affine=pop_crop.rio.transform(),\n",
    "        stats=[\"sum\"],\n",
    "        nodata=pop_crop.rio.nodata,\n",
    "        all_touched=True)\n",
    "    \n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        admin2_records.append({\n",
    "            \"admin2\": row.admin2,\n",
    "            \"year\": year,\n",
    "            \"population\": admin2_pop_stats[i][\"sum\"]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_admin1_pop = pd.DataFrame(admin1_records)\n",
    "df_admin2_pop = pd.DataFrame(admin2_records)\n",
    "\n",
    "# Optional: reset index\n",
    "df_admin1_pop = df_admin1_pop.reset_index(drop=True)\n",
    "df_admin2_pop = df_admin2_pop.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f715cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.path.join(folder, \"admin_year_pop\")\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "df_admin1_pop.to_csv(os.path.join(out_folder, \"admin1_year_pop.csv\"), index=False)\n",
    "df_admin2_pop.to_csv(os.path.join(out_folder, \"admin2_year_pop.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7624b1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### urbanisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87087b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1 resolution: 0.008333333333333304 -0.008333333333333297\n",
      "r2 resolution: 0.009961733526091017 -0.009961733526091015\n",
      "r2 is lower resolution, downsampling r2 to r1\n"
     ]
    }
   ],
   "source": [
    "admin1_records = []\n",
    "admin2_records = []\n",
    "\n",
    "# population-aligned urbanisation raster\n",
    "_, raster_urbanisation_binary_pop_aligned = best_res_align(raster_pop[2015], '',\n",
    "                                                    raster_urbanisation_binary, 'nearest',\n",
    "                                                    region_bounds_buffered = region_bounds_buffered,\n",
    "                                                    shape_crs = admin1_shp.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d122498",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015,2025):\n",
    "    pop_crop = raster_pop[year].squeeze().rio.clip_box(minx=region_bounds_buffered[0], miny=region_bounds_buffered[1],\n",
    "                                                   maxx=region_bounds_buffered[2], maxy=region_bounds_buffered[3])\n",
    "    # admin1\n",
    "    # Non-weighted: simple mean over each polygon\n",
    "    urbanisation_nonweighted = zonal_stats(\n",
    "        vectors=admin1_shp,\n",
    "        raster=raster_urbanisation_binary_pop_aligned.values,\n",
    "        affine=raster_urbanisation_binary_pop_aligned.rio.transform(),\n",
    "        stats=[\"mean\"],\n",
    "        nodata=raster_urbanisation_binary_pop_aligned.rio.nodata,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Population-weighted: sum(urban * pop) / sum(pop)\n",
    "    urbanisation_pop_weighted_records = []\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                         out_shape=raster_urbanisation_binary_pop_aligned.shape[-2:],\n",
    "                         transform=raster_urbanisation_binary_pop_aligned.rio.transform(),\n",
    "                         fill=0,\n",
    "                         all_touched=True,\n",
    "                         dtype=\"uint8\"\n",
    "                         ).astype(bool)\n",
    "        urbanisation_values = raster_urbanisation_binary_pop_aligned.values[mask]\n",
    "        pop_values = pop_crop.values[mask]\n",
    "\n",
    "        # Keep only cells where BOTH are valid\n",
    "        valid = (~np.isnan(urbanisation_values)) & (~np.isnan(pop_values)) & (pop_values > 0)\n",
    "\n",
    "        if not np.any(valid):\n",
    "            weighted_mean = np.nan\n",
    "        else:\n",
    "            weighted_mean = np.sum(urbanisation_values[valid] * pop_values[valid]) / np.sum(pop_values[valid])\n",
    "        urbanisation_pop_weighted_records.append(weighted_mean)\n",
    "\n",
    "    # Store results in admin1_records\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        admin1_records.append({\n",
    "            \"admin1\": row.admin1,\n",
    "            \"year\": year,\n",
    "            \"urbanisation_nonweighted\": urbanisation_nonweighted[i][\"mean\"],\n",
    "            \"urbanisation_pop_weighted\": urbanisation_pop_weighted_records[i]\n",
    "        })\n",
    "\n",
    "    # admin2\n",
    "    # Non-weighted: simple mean over each polygon\n",
    "    urbanisation_nonweighted = zonal_stats(\n",
    "        vectors=admin2_shp,\n",
    "        raster=raster_urbanisation_binary_pop_aligned.values,\n",
    "        affine=raster_urbanisation_binary_pop_aligned.rio.transform(),\n",
    "        stats=[\"mean\"],\n",
    "        nodata=raster_urbanisation_binary_pop_aligned.rio.nodata,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Population-weighted: sum(urban * pop) / sum(pop)\n",
    "    urbanisation_pop_weighted_records = []\n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                         out_shape=raster_urbanisation_binary_pop_aligned.shape[-2:],\n",
    "                         transform=raster_urbanisation_binary_pop_aligned.rio.transform(),\n",
    "                         fill=0,\n",
    "                         all_touched=True,\n",
    "                         dtype=\"uint8\"\n",
    "                         ).astype(bool)\n",
    "        urbanisation_values = raster_urbanisation_binary_pop_aligned.values[mask]\n",
    "        pop_values = pop_crop.values[mask]\n",
    "\n",
    "        # Keep only cells where BOTH are valid\n",
    "        valid = (~np.isnan(urbanisation_values)) & (~np.isnan(pop_values)) & (pop_values > 0)\n",
    "\n",
    "        if not np.any(valid):\n",
    "            weighted_mean = np.nan\n",
    "        else:\n",
    "            weighted_mean = np.sum(urbanisation_values[valid] * pop_values[valid]) / np.sum(pop_values[valid])\n",
    "        urbanisation_pop_weighted_records.append(weighted_mean)\n",
    "\n",
    "    # Store results in admin2_records\n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        admin2_records.append({\n",
    "            \"admin2\": row.admin2,\n",
    "            \"year\": year,\n",
    "            \"urbanisation_nonweighted\": urbanisation_nonweighted[i][\"mean\"],\n",
    "            \"urbanisation_pop_weighted\": urbanisation_pop_weighted_records[i]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_admin1_urbanisation = pd.DataFrame(admin1_records)\n",
    "df_admin2_urbanisation = pd.DataFrame(admin2_records)\n",
    "\n",
    "# Optional: reset index\n",
    "df_admin1_urbanisation = df_admin1_urbanisation.reset_index(drop=True)\n",
    "df_admin2_urbanisation = df_admin2_urbanisation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfa3d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin2</th>\n",
       "      <th>year</th>\n",
       "      <th>urbanisation_nonweighted</th>\n",
       "      <th>urbanisation_pop_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACEH BARAT</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>0.224615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEH BARAT DAYA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.037194</td>\n",
       "      <td>0.666287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEH BESAR</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.099596</td>\n",
       "      <td>0.589342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACEH JAYA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.256873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACEH SELATAN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.038308</td>\n",
       "      <td>0.405260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>WAY KANAN</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.045294</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>WONOGIRI</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.453802</td>\n",
       "      <td>0.694331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>WONOSOBO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.513472</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>YAHUKIMO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>0.069001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>YALIMO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.579640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               admin2  year  urbanisation_nonweighted  \\\n",
       "0          ACEH BARAT  2015                  0.018364   \n",
       "1     ACEH BARAT DAYA  2015                  0.037194   \n",
       "2          ACEH BESAR  2015                  0.099596   \n",
       "3           ACEH JAYA  2015                  0.009563   \n",
       "4        ACEH SELATAN  2015                  0.038308   \n",
       "...               ...   ...                       ...   \n",
       "5135        WAY KANAN  2024                  0.045294   \n",
       "5136         WONOGIRI  2024                  0.453802   \n",
       "5137         WONOSOBO  2024                  0.513472   \n",
       "5138         YAHUKIMO  2024                  0.008076   \n",
       "5139           YALIMO  2024                  0.018722   \n",
       "\n",
       "      urbanisation_pop_weighted  \n",
       "0                      0.224615  \n",
       "1                      0.666287  \n",
       "2                      0.589342  \n",
       "3                      0.256873  \n",
       "4                      0.405260  \n",
       "...                         ...  \n",
       "5135                   0.231300  \n",
       "5136                   0.694331  \n",
       "5137                   0.795368  \n",
       "5138                   0.069001  \n",
       "5139                   0.579640  \n",
       "\n",
       "[5140 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_admin2_urbanisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6883162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.path.join(folder, \"admin_year_urbanisation\")\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "df_admin1_urbanisation.to_csv(os.path.join(out_folder, \"admin1_year_urbanisation.csv\"), index=False)\n",
    "df_admin2_urbanisation.to_csv(os.path.join(out_folder, \"admin2_year_urbanisation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b189c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### surveillance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041e2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1 resolution: 0.008333333333333304 -0.008333333333333297\n",
      "r2 resolution: 0.04166666666662877 -0.04166666666665719\n",
      "r2 is lower resolution, downsampling r2 to r1\n"
     ]
    }
   ],
   "source": [
    "admin1_records = []\n",
    "admin2_records = []\n",
    "\n",
    "# population-aligned surveillance raster\n",
    "_, raster_surveillance_pop_aligned = best_res_align(raster_pop[2015], '',\n",
    "                                                    raster_surveillance, 'nearest',\n",
    "                                                    region_bounds_buffered = region_bounds_buffered,\n",
    "                                                    shape_crs = admin1_shp.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34657cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015,2025):\n",
    "    pop_crop = raster_pop[year].squeeze().rio.clip_box(minx=region_bounds_buffered[0], miny=region_bounds_buffered[1],\n",
    "                                                   maxx=region_bounds_buffered[2], maxy=region_bounds_buffered[3])\n",
    "    # admin1\n",
    "    # Non-weighted: simple mean over each polygon\n",
    "    surveillance_nonweighted = zonal_stats(\n",
    "        vectors=admin1_shp,\n",
    "        raster=raster_surveillance_pop_aligned.values,\n",
    "        affine=raster_surveillance_pop_aligned.rio.transform(),\n",
    "        stats=[\"mean\"],\n",
    "        nodata=raster_surveillance_pop_aligned.rio.nodata,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Population-weighted: sum(surveillance * pop) / sum(pop)\n",
    "    pop_weighted_records = []\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                         out_shape=raster_surveillance_pop_aligned.shape[-2:],\n",
    "                         transform=raster_surveillance_pop_aligned.rio.transform(),\n",
    "                         fill=0,\n",
    "                         all_touched=True,\n",
    "                         dtype=\"uint8\"\n",
    "                         ).astype(bool)\n",
    "        surveillance_values = raster_surveillance_pop_aligned.values[mask]\n",
    "        pop_values = pop_crop.values[mask]\n",
    "\n",
    "        # Keep only cells where BOTH are valid\n",
    "        valid = (~np.isnan(surveillance_values)) & (~np.isnan(pop_values)) & (pop_values > 0)\n",
    "\n",
    "        if not np.any(valid):\n",
    "            weighted_mean = np.nan\n",
    "        else:\n",
    "            weighted_mean = np.sum(surveillance_values[valid] * pop_values[valid]) / np.sum(pop_values[valid])\n",
    "        pop_weighted_records.append(weighted_mean)\n",
    "\n",
    "    # Store results in admin1_records\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        admin1_records.append({\n",
    "            \"admin1\": row.admin1,\n",
    "            \"year\": year,\n",
    "            \"surveillance_nonweighted\": surveillance_nonweighted[i][\"mean\"],\n",
    "            \"surveillance_pop_weighted\": pop_weighted_records[i]\n",
    "        })\n",
    "\n",
    "    # admin2\n",
    "    # Non-weighted: simple mean over each polygon\n",
    "    surveillance_nonweighted = zonal_stats(\n",
    "        vectors=admin2_shp,\n",
    "        raster=raster_surveillance_pop_aligned.values,\n",
    "        affine=raster_surveillance_pop_aligned.rio.transform(),\n",
    "        stats=[\"mean\"],\n",
    "        nodata=raster_surveillance_pop_aligned.rio.nodata,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Population-weighted: sum(surveillance * pop) / sum(pop)\n",
    "    pop_weighted_records = []\n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                         out_shape=raster_surveillance_pop_aligned.shape[-2:],\n",
    "                         transform=raster_surveillance_pop_aligned.rio.transform(),\n",
    "                         fill=0,\n",
    "                         all_touched=True,\n",
    "                         dtype=\"uint8\"\n",
    "                         ).astype(bool)\n",
    "        surveillance_values = raster_surveillance_pop_aligned.values[mask]\n",
    "        pop_values = pop_crop.values[mask]\n",
    "\n",
    "        # Keep only cells where BOTH are valid\n",
    "        valid = (~np.isnan(surveillance_values)) & (~np.isnan(pop_values)) & (pop_values > 0)\n",
    "\n",
    "        if not np.any(valid):\n",
    "            weighted_mean = np.nan\n",
    "        else:\n",
    "            weighted_mean = np.sum(surveillance_values[valid] * pop_values[valid]) / np.sum(pop_values[valid])\n",
    "        pop_weighted_records.append(weighted_mean)\n",
    "        \n",
    "    # Store results in admin1_records\n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        admin2_records.append({\n",
    "            \"admin2\": row.admin2,\n",
    "            \"year\": year,\n",
    "            \"surveillance_nonweighted\": surveillance_nonweighted[i][\"mean\"],\n",
    "            \"surveillance_pop_weighted\": pop_weighted_records[i]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_admin1_surveillance = pd.DataFrame(admin1_records)\n",
    "df_admin2_surveillance = pd.DataFrame(admin2_records)\n",
    "\n",
    "# Optional: reset index\n",
    "df_admin1_surveillance = df_admin1_surveillance.reset_index(drop=True)\n",
    "df_admin2_surveillance = df_admin2_surveillance.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a85bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin2</th>\n",
       "      <th>year</th>\n",
       "      <th>surveillance_nonweighted</th>\n",
       "      <th>surveillance_pop_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACEH BARAT</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.369001</td>\n",
       "      <td>0.639564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEH BARAT DAYA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.297746</td>\n",
       "      <td>0.740813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEH BESAR</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.510617</td>\n",
       "      <td>0.858704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACEH JAYA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.236977</td>\n",
       "      <td>0.572931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACEH SELATAN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.233088</td>\n",
       "      <td>0.498598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>WAY KANAN</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.515941</td>\n",
       "      <td>0.606863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>WONOGIRI</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.838876</td>\n",
       "      <td>0.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>WONOSOBO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.848702</td>\n",
       "      <td>0.882246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>YAHUKIMO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.057116</td>\n",
       "      <td>0.077861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>YALIMO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.071654</td>\n",
       "      <td>0.206443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               admin2  year  surveillance_nonweighted  \\\n",
       "0          ACEH BARAT  2015                  0.369001   \n",
       "1     ACEH BARAT DAYA  2015                  0.297746   \n",
       "2          ACEH BESAR  2015                  0.510617   \n",
       "3           ACEH JAYA  2015                  0.236977   \n",
       "4        ACEH SELATAN  2015                  0.233088   \n",
       "...               ...   ...                       ...   \n",
       "5135        WAY KANAN  2024                  0.515941   \n",
       "5136         WONOGIRI  2024                  0.838876   \n",
       "5137         WONOSOBO  2024                  0.848702   \n",
       "5138         YAHUKIMO  2024                  0.057116   \n",
       "5139           YALIMO  2024                  0.071654   \n",
       "\n",
       "      surveillance_pop_weighted  \n",
       "0                      0.639564  \n",
       "1                      0.740813  \n",
       "2                      0.858704  \n",
       "3                      0.572931  \n",
       "4                      0.498598  \n",
       "...                         ...  \n",
       "5135                   0.606863  \n",
       "5136                   0.870500  \n",
       "5137                   0.882246  \n",
       "5138                   0.077861  \n",
       "5139                   0.206443  \n",
       "\n",
       "[5140 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_admin2_surveillance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e13f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.path.join(folder, \"admin_year_surveillance\")\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "df_admin1_surveillance.to_csv(os.path.join(out_folder, \"admin1_year_surveillance.csv\"), index=False)\n",
    "df_admin2_surveillance.to_csv(os.path.join(out_folder, \"admin2_year_surveillance.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4af9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### urban surveillance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f756b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_records = []\n",
    "admin2_records = []\n",
    "raster_urbanisation_binary_pop_aligned_mask = raster_urbanisation_binary_pop_aligned.where(raster_urbanisation_binary_pop_aligned==1, other=np.nan)\n",
    "raster_urban_surveillance_pop_aligned = raster_surveillance_pop_aligned * raster_urbanisation_binary_pop_aligned_mask\n",
    "raster_urban_surveillance_pop_aligned = raster_urban_surveillance_pop_aligned.rio.write_nodata(np.nan, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "355fc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015,2025):\n",
    "    pop_crop = raster_pop[year].squeeze().rio.clip_box(minx=region_bounds_buffered[0], miny=region_bounds_buffered[1],\n",
    "                                                   maxx=region_bounds_buffered[2], maxy=region_bounds_buffered[3])\n",
    "    # admin1\n",
    "    # Non-weighted: simple mean over each polygon\n",
    "    urban_surveillance_nonweighted = zonal_stats(\n",
    "        vectors=admin1_shp,\n",
    "        raster=raster_urban_surveillance_pop_aligned.values,\n",
    "        affine=raster_urban_surveillance_pop_aligned.rio.transform(),\n",
    "        stats=[\"mean\"],\n",
    "        nodata=raster_urban_surveillance_pop_aligned.rio.nodata,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Population-weighted: sum(surveillance * pop) / sum(pop)\n",
    "    urban_surveillance_pop_weighted_records = []\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                         out_shape=raster_urban_surveillance_pop_aligned.shape[-2:],\n",
    "                         transform=raster_urban_surveillance_pop_aligned.rio.transform(),\n",
    "                         fill=0,\n",
    "                         all_touched=True,\n",
    "                         dtype=\"uint8\"\n",
    "                         ).astype(bool)\n",
    "        urban_surveillance_values = raster_urban_surveillance_pop_aligned.values[mask]\n",
    "        pop_values = pop_crop.values[mask]\n",
    "\n",
    "        # Keep only cells where BOTH are valid\n",
    "        valid = (~np.isnan(urban_surveillance_values)) & (~np.isnan(pop_values)) & (pop_values > 0)\n",
    "\n",
    "        if not np.any(valid):\n",
    "            weighted_mean = np.nan\n",
    "        else:\n",
    "            weighted_mean = np.sum(urban_surveillance_values[valid] * pop_values[valid]) / np.sum(pop_values[valid])\n",
    "        urban_surveillance_pop_weighted_records.append(weighted_mean)\n",
    "        \n",
    "    # Store results in admin1_records\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        admin1_records.append({\n",
    "            \"admin1\": row.admin1,\n",
    "            \"year\": year,\n",
    "            \"urban_surveillance_nonweighted\": urban_surveillance_nonweighted[i][\"mean\"],\n",
    "            \"urban_surveillance_pop_weighted\": urban_surveillance_pop_weighted_records[i]\n",
    "        })\n",
    "\n",
    "    # admin2\n",
    "    # Non-weighted: simple mean over each polygon\n",
    "    urban_surveillance_nonweighted = zonal_stats(\n",
    "        vectors=admin2_shp,\n",
    "        raster=raster_urban_surveillance_pop_aligned.values,\n",
    "        affine=raster_urban_surveillance_pop_aligned.rio.transform(),\n",
    "        stats=[\"mean\"],\n",
    "        nodata=raster_urban_surveillance_pop_aligned.rio.nodata,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Population-weighted: sum(surveillance * pop) / sum(pop)\n",
    "    urban_surveillance_pop_weighted_records = []\n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                         out_shape=raster_urban_surveillance_pop_aligned.shape[-2:],\n",
    "                         transform=raster_urban_surveillance_pop_aligned.rio.transform(),\n",
    "                         fill=0,\n",
    "                         all_touched=True,\n",
    "                         dtype=\"uint8\"\n",
    "                         ).astype(bool)\n",
    "        urban_surveillance_values = raster_urban_surveillance_pop_aligned.values[mask]\n",
    "        pop_values = pop_crop.values[mask]\n",
    "\n",
    "        # Keep only cells where BOTH are valid\n",
    "        valid = (~np.isnan(urban_surveillance_values)) & (~np.isnan(pop_values)) & (pop_values > 0)\n",
    "\n",
    "        if not np.any(valid):\n",
    "            weighted_mean = np.nan\n",
    "        else:\n",
    "            weighted_mean = np.sum(urban_surveillance_values[valid] * pop_values[valid]) / np.sum(pop_values[valid])\n",
    "        urban_surveillance_pop_weighted_records.append(weighted_mean)\n",
    "        \n",
    "    # Store results in admin2_records\n",
    "    for i, row in enumerate(admin2_shp.itertuples()):\n",
    "        admin2_records.append({\n",
    "            \"admin2\": row.admin2,\n",
    "            \"year\": year,\n",
    "            \"urban_surveillance_nonweighted\": urban_surveillance_nonweighted[i][\"mean\"],\n",
    "            \"urban_surveillance_pop_weighted\": urban_surveillance_pop_weighted_records[i]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_admin1_urban_surveillance = pd.DataFrame(admin1_records)\n",
    "df_admin2_urban_surveillance = pd.DataFrame(admin2_records)\n",
    "\n",
    "# Optional: reset index\n",
    "df_admin1_urban_surveillance = df_admin1_urban_surveillance.reset_index(drop=True)\n",
    "df_admin2_urban_surveillance = df_admin2_urban_surveillance.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3fe6488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin2</th>\n",
       "      <th>year</th>\n",
       "      <th>urban_surveillance_nonweighted</th>\n",
       "      <th>urban_surveillance_pop_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACEH BARAT</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.829057</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEH BARAT DAYA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.844500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEH BESAR</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.915559</td>\n",
       "      <td>0.939699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACEH JAYA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.864509</td>\n",
       "      <td>0.879474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACEH SELATAN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.694324</td>\n",
       "      <td>0.680381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>WAY KANAN</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.765571</td>\n",
       "      <td>0.760155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>WONOGIRI</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.868872</td>\n",
       "      <td>0.888670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>WONOSOBO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.864985</td>\n",
       "      <td>0.891884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>YAHUKIMO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.171283</td>\n",
       "      <td>0.184696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>YALIMO</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.152738</td>\n",
       "      <td>0.270802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5654 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               admin2  year  urban_surveillance_nonweighted  \\\n",
       "0          ACEH BARAT  2015                        0.829057   \n",
       "1     ACEH BARAT DAYA  2015                        0.825269   \n",
       "2          ACEH BESAR  2015                        0.915559   \n",
       "3           ACEH JAYA  2015                        0.864509   \n",
       "4        ACEH SELATAN  2015                        0.694324   \n",
       "...               ...   ...                             ...   \n",
       "5649        WAY KANAN  2024                        0.765571   \n",
       "5650         WONOGIRI  2024                        0.868872   \n",
       "5651         WONOSOBO  2024                        0.864985   \n",
       "5652         YAHUKIMO  2024                        0.171283   \n",
       "5653           YALIMO  2024                        0.152738   \n",
       "\n",
       "      urban_surveillance_pop_weighted  \n",
       "0                            0.787234  \n",
       "1                            0.844500  \n",
       "2                            0.939699  \n",
       "3                            0.879474  \n",
       "4                            0.680381  \n",
       "...                               ...  \n",
       "5649                         0.760155  \n",
       "5650                         0.888670  \n",
       "5651                         0.891884  \n",
       "5652                         0.184696  \n",
       "5653                         0.270802  \n",
       "\n",
       "[5654 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_admin2_urban_surveillance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ab52503",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.path.join(folder, \"admin_year_urban_surveillance\")\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "df_admin1_surveillance.to_csv(os.path.join(out_folder, \"admin1_year_urban_surveillance.csv\"), index=False)\n",
    "df_admin2_surveillance.to_csv(os.path.join(out_folder, \"admin2_year_urban_surveillance.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef1912",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### climate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d90414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_folder = os.path.join(folder, \"weather_statistics-(reanalysis-era5-land)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d79ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_records = []\n",
    "admin2_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0380ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = xr.open_dataset(os.path.join(weather_folder, f\"t2m/t2m_{year}.grib\"),engine=\"cfgrib\")\n",
    "t2m = t2m.isel(time=slice(1, None))\n",
    "t2m = t2m['t2m']\n",
    "t2m = t2m.rio.write_crs(\"EPSG:4326\")\n",
    "# t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4fb1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = xr.open_dataset(os.path.join(weather_folder, f\"tp/tp_{year}.grib\"),engine=\"cfgrib\")\n",
    "tp = tp.isel(time=slice(1, None))\n",
    "tp = tp['tp']\n",
    "tp = tp.rio.write_crs(\"EPSG:4326\")\n",
    "# tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bdaf53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = xr.open_dataset(os.path.join(weather_folder, f\"rh/rh_{year}.nc\"),engine=\"netcdf4\")\n",
    "rh = rh['rh']\n",
    "rh = rh.rio.write_crs(\"EPSG:4326\")\n",
    "# rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4997e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_dict = {}\n",
    "admin2_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c65d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_monthly_mean = {}\n",
    "t2m_monthly_min = {}\n",
    "t2m_monthly_max = {}\n",
    "tp_monthly_mean = {}\n",
    "rh_monthly_mean = {}\n",
    "\n",
    "pixel_monthly_statistics = {}\n",
    "\n",
    "t2m_monthly_mean_aligned = {}\n",
    "t2m_monthly_min_aligned = {}\n",
    "t2m_monthly_max_aligned = {}\n",
    "tp_monthly_mean_aligned = {}\n",
    "rh_monthly_mean_aligned = {}\n",
    "\n",
    "pixel_monthly_statistics_aligned = {}\n",
    "\n",
    "stat_names = [\"t2m_mean\", \"t2m_min\", \"t2m_max\", \"tp_mean\", \"rh_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8765c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015,2025):\n",
    "    # read in climate data datasets\n",
    "    t2m = xr.open_dataset(os.path.join(weather_folder, f\"t2m/t2m_{year}.grib\"),engine=\"cfgrib\")\n",
    "    t2m = t2m.isel(time=slice(1, None))\n",
    "    t2m = t2m['t2m']\n",
    "    t2m = t2m.rio.write_crs(\"EPSG:4326\")\n",
    "    tp = xr.open_dataset(os.path.join(weather_folder, f\"tp/tp_{year}.grib\"),engine=\"cfgrib\")\n",
    "    tp = tp.isel(time=slice(1, None))\n",
    "    tp = tp['tp']\n",
    "    tp = tp.rio.write_crs(\"EPSG:4326\")\n",
    "    rh = xr.open_dataset(os.path.join(weather_folder, f\"rh/rh_{year}.nc\"),engine=\"netcdf4\")\n",
    "    rh = rh['rh']\n",
    "    rh = rh.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    # calculate monthly pixel statistics\n",
    "    t2m['time'] = pd.to_datetime(t2m['time'].values)\n",
    "    t2m_monthly_mean[year] = t2m.groupby('time.month').mean(dim=['time', 'step'])\n",
    "    t2m_monthly_min[year] = t2m.groupby('time.month').min(dim=['time', 'step'])\n",
    "    t2m_monthly_max[year] = t2m.groupby('time.month').max(dim=['time', 'step'])\n",
    "\n",
    "    tp['time'] = pd.to_datetime(tp['time'].values)\n",
    "    tp_monthly_mean[year] = tp.groupby('time.month').mean(dim=['time', 'step'])\n",
    "\n",
    "    rh['time'] = pd.to_datetime(rh['time'].values)\n",
    "    rh_monthly_mean[year] = rh.groupby('time.month').mean(dim=['time', 'step'])\n",
    "\n",
    "    # align\n",
    "    align_methods = {\"t2m_mean\": \"bilinear\",\n",
    "                     \"t2m_min\":  \"nearest\",\n",
    "                     \"t2m_max\":  \"nearest\",\n",
    "                     \"tp_mean\":  \"bilinear\",\n",
    "                     \"rh_mean\":  \"bilinear\"}\n",
    "    \n",
    "    _, t2m_monthly_mean_aligned[year] = best_res_align(pop_crop_alignment, '',\n",
    "                                            t2m_monthly_mean[year], align_methods['t2m_mean'],\n",
    "                                            region_bounds_buffered = region_bounds_buffered,\n",
    "                                            shape_crs = admin1_shp.crs)\n",
    "    _, t2m_monthly_min_aligned[year] = best_res_align(pop_crop_alignment, '',\n",
    "                                            t2m_monthly_min[year], align_methods['t2m_min'],\n",
    "                                            region_bounds_buffered = region_bounds_buffered,\n",
    "                                            shape_crs = admin1_shp.crs)\n",
    "    _, t2m_monthly_max_aligned[year] = best_res_align(pop_crop_alignment, '',\n",
    "                                            t2m_monthly_max[year], align_methods['t2m_max'],\n",
    "                                            region_bounds_buffered = region_bounds_buffered,\n",
    "                                            shape_crs = admin1_shp.crs)\n",
    "    _, tp_monthly_mean_aligned[year] = best_res_align(pop_crop_alignment, '',\n",
    "                                            tp_monthly_mean[year], align_methods['tp_mean'],\n",
    "                                            region_bounds_buffered = region_bounds_buffered,\n",
    "                                            shape_crs = admin1_shp.crs)\n",
    "    _, rh_monthly_mean_aligned[year] = best_res_align(pop_crop_alignment, '',\n",
    "                                            rh_monthly_mean[year], align_methods['rh_mean'],\n",
    "                                            region_bounds_buffered = region_bounds_buffered,\n",
    "                                            shape_crs = admin1_shp.crs)\n",
    "\n",
    "pixel_monthly_statistics = {\"t2m_mean\" : t2m_monthly_mean,\n",
    "                            \"t2m_min\" : t2m_monthly_min,\n",
    "                            \"t2m_max\" : t2m_monthly_max,\n",
    "                            \"tp_mean\" : tp_monthly_mean,\n",
    "                            \"rh_mean\" : rh_monthly_mean}\n",
    "pixel_monthly_statistics_aligned = {\"t2m_mean\" : t2m_monthly_mean_aligned,\n",
    "                                    \"t2m_min\" : t2m_monthly_min_aligned,\n",
    "                                    \"t2m_max\" : t2m_monthly_max_aligned,\n",
    "                                    \"tp_mean\" : tp_monthly_mean_aligned,\n",
    "                                    \"rh_mean\" : rh_monthly_mean_aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fa14604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2m_mean\n",
      "2015\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "2016\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "t2m_min\n",
      "2015\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "2016\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "t2m_max\n",
      "2015\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "2016\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "tp_mean\n",
      "2015\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "2016\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "rh_mean\n",
      "2015\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n",
      "2016\n",
      "ACEH\n",
      "BALI\n",
      "ACEH BARAT\n",
      "ACEH BARAT DAYA\n"
     ]
    }
   ],
   "source": [
    "admin1_dict = {}\n",
    "admin2_dict = {}\n",
    "for stat_name in stat_names[:]:\n",
    "    print(stat_name)\n",
    "    for year in range(2015,2017):\n",
    "        print(year)\n",
    "        pixel_statistic_aligned = pixel_monthly_statistics_aligned[stat_name][year]\n",
    "\n",
    "        # admin1\n",
    "        statistic_unweighted_records_1 = []\n",
    "        statistic_pop_weighted_records_1 = []\n",
    "\n",
    "        for i, row in enumerate(admin1_shp.itertuples()):\n",
    "            if i>1:\n",
    "                break\n",
    "            print(row.admin1)\n",
    "            mask = rasterize([(row.geometry, 1)],\n",
    "                                out_shape=pixel_statistic_aligned.shape[-2:],\n",
    "                                transform=pixel_statistic_aligned.rio.transform(),\n",
    "                                fill=0,\n",
    "                                all_touched=True,\n",
    "                                dtype=\"uint8\"\n",
    "                                ).astype(bool)\n",
    "            statistic_values = np.where(mask, pixel_statistic_aligned.values, np.nan)\n",
    "            pop_values = np.where(mask, pop_crop_alignment.values, np.nan)\n",
    "            pop_values_b = np.broadcast_to(pop_values, statistic_values.shape)\n",
    "            if np.all(np.isnan(statistic_values)):\n",
    "                print('all nan')\n",
    "                continue\n",
    "            unweighted_mean_per_month = np.nanmean(statistic_values, axis=(1,2))\n",
    "            statistic_unweighted_records_1.append(unweighted_mean_per_month)\n",
    "\n",
    "            valid = (~np.isnan(statistic_values)) & (~np.isnan(pop_values_b))\n",
    "            weighted_sum = np.nansum(statistic_values * pop_values_b * valid, axis=(1,2))\n",
    "            pop_sum = np.nansum(pop_values_b * valid, axis=(1,2))\n",
    "            \n",
    "            pop_weighted_mean_per_month = weighted_sum / pop_sum\n",
    "            statistic_pop_weighted_records_1.append(pop_weighted_mean_per_month)\n",
    "\n",
    "            for month in range(1, statistic_values.shape[0]+1):\n",
    "                key = (row.admin1, year, month)\n",
    "                if key not in admin1_dict:\n",
    "                    admin1_dict[key] = {\n",
    "                        \"admin1\": row.admin1,\n",
    "                        \"year\": year,\n",
    "                        \"month\": month\n",
    "                    }\n",
    "                admin1_dict[key][f\"{stat_name}_unweighted\"] = unweighted_mean_per_month[month-1]\n",
    "                admin1_dict[key][f\"{stat_name}_pop_weighted\"] = pop_weighted_mean_per_month[month-1]\n",
    "\n",
    "        # admin2\n",
    "        statistic_unweighted_records_2 = []\n",
    "        statistic_pop_weighted_records_2 = []\n",
    "\n",
    "        for i, row in enumerate(admin2_shp.itertuples()):\n",
    "            if i>1:\n",
    "                break\n",
    "            print(row.admin2)\n",
    "            mask = rasterize([(row.geometry, 1)],\n",
    "                                out_shape=pixel_statistic_aligned.shape[-2:],\n",
    "                                transform=pixel_statistic_aligned.rio.transform(),\n",
    "                                fill=0,\n",
    "                                all_touched=True,\n",
    "                                dtype=\"uint8\"\n",
    "                                ).astype(bool)\n",
    "            statistic_values = np.where(mask, pixel_statistic_aligned.values, np.nan)\n",
    "            pop_values = np.where(mask, pop_crop_alignment.values, np.nan)\n",
    "            pop_values_b = np.broadcast_to(pop_values, statistic_values.shape)\n",
    "            if np.all(np.isnan(statistic_values)):\n",
    "                print('all nan')\n",
    "                continue\n",
    "            unweighted_mean_per_month = np.nanmean(statistic_values, axis=(1,2))\n",
    "            statistic_unweighted_records_2.append(unweighted_mean_per_month)\n",
    "\n",
    "            valid = (~np.isnan(statistic_values)) & (~np.isnan(pop_values_b))\n",
    "            weighted_sum = np.nansum(statistic_values * pop_values_b * valid, axis=(1,2))\n",
    "            pop_sum = np.nansum(pop_values_b * valid, axis=(1,2))\n",
    "            \n",
    "            pop_weighted_mean_per_month = weighted_sum / pop_sum\n",
    "            statistic_pop_weighted_records_2.append(pop_weighted_mean_per_month)\n",
    "\n",
    "            for month in range(1, statistic_values.shape[0]+1):\n",
    "                key = (row.admin2, year, month)\n",
    "                if key not in admin2_dict:\n",
    "                    admin2_dict[key] = {\n",
    "                        \"admin2\": row.admin2,\n",
    "                        \"year\": year,\n",
    "                        \"month\": month\n",
    "                    }\n",
    "                admin2_dict[key][f\"{stat_name}_unweighted\"] = unweighted_mean_per_month[month-1]\n",
    "                admin2_dict[key][f\"{stat_name}_pop_weighted\"] = pop_weighted_mean_per_month[month-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb11bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "admin1_records = list(admin1_dict.values())\n",
    "df_admin1_statistics = pd.DataFrame(admin1_records)\n",
    "df_admin1_statistics = df_admin1_statistics.sort_values(by=[\"admin1\", \"year\", \"month\"]).reset_index(drop=True)\n",
    "\n",
    "admin2_records = list(admin2_dict.values())\n",
    "df_admin2_statistics = pd.DataFrame(admin2_records)\n",
    "df_admin2_statistics = df_admin2_statistics.sort_values(by=[\"admin2\", \"year\", \"month\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da966b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admin1_statistics.to_csv(os.path.join(folder, 'df_admin1_statistics.csv'), index=False)\n",
    "df_admin2_statistics.to_csv(os.path.join(folder, 'df_admin2_statistics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799b6f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "980f25a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2m_mean\n",
      "ACEH\n",
      "BALI\n",
      "t2m_min\n",
      "ACEH\n",
      "BALI\n"
     ]
    }
   ],
   "source": [
    "f_admin1_dict = {}\n",
    "f_admin2_dict = {}\n",
    "for stat_name in stat_names[:2]:\n",
    "    print(stat_name)\n",
    "    \n",
    "    years = list(range(2015, 2017))\n",
    "    pixel_statistic_stacked = xr.concat(\n",
    "        [pixel_monthly_statistics_aligned[stat_name][y] for y in years],\n",
    "        dim=\"year\")\n",
    "    pixel_statistic_stacked = pixel_statistic_stacked.assign_coords(year=years)\n",
    "\n",
    "    # admin1\n",
    "    for i, row in enumerate(admin1_shp.itertuples()):\n",
    "        if i>1:\n",
    "            break\n",
    "        print(row.admin1)\n",
    "        mask = rasterize([(row.geometry, 1)],\n",
    "                            out_shape=pixel_statistic_stacked.shape[-2:],\n",
    "                            transform=pixel_statistic_stacked.rio.transform(),\n",
    "                            fill=0,\n",
    "                            all_touched=True,\n",
    "                            dtype=\"uint8\"\n",
    "                            ).astype(bool)\n",
    "        statistic_values = np.where(mask, pixel_statistic_stacked.values, np.nan)\n",
    "        pop_values = np.where(mask, pop_crop_alignment.values, np.nan)\n",
    "        pop_values_b = np.broadcast_to(pop_values, statistic_values.shape)\n",
    "        \n",
    "        unweighted_mean_per_month = np.nanmean(statistic_values, axis=(2,3))\n",
    "\n",
    "        valid = (~np.isnan(statistic_values)) & (~np.isnan(pop_values_b))\n",
    "        weighted_sum = np.nansum(statistic_values * pop_values_b * valid, axis=(2,3))\n",
    "        pop_sum = np.nansum(pop_values_b * valid, axis=(2,3))\n",
    "        \n",
    "        pop_weighted_mean_per_month = weighted_sum / pop_sum\n",
    "\n",
    "        for year in range(2015, statistic_values.shape[0]+2015):\n",
    "            for month in range(1, statistic_values.shape[1]+1):\n",
    "                key = (row.admin1, year, month)\n",
    "                if key not in f_admin1_dict:\n",
    "                    f_admin1_dict[key] = {\n",
    "                        \"admin1\": row.admin1,\n",
    "                        \"year\": year,\n",
    "                        \"month\": month\n",
    "                    }\n",
    "                f_admin1_dict[key][f\"{stat_name}_unweighted\"] = unweighted_mean_per_month[year-2015, month-1]\n",
    "                f_admin1_dict[key][f\"{stat_name}_pop_weighted\"] = pop_weighted_mean_per_month[year-2015, month-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fbedcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 2094, 5565)\n",
      "ACEH\n",
      "(48, 2094, 5565)\n",
      "BALI\n",
      "(48, 2094, 5565)\n"
     ]
    }
   ],
   "source": [
    "f_admin1_dict = {}\n",
    "f_admin2_dict = {}\n",
    "\n",
    "# concatenate datasets\n",
    "years = list(range(2015, 2017))\n",
    "pixel_statistic_stacked = xr.concat(\n",
    "    [pixel_monthly_statistics_aligned[stat_name][y] for stat_name in stat_names[:2] for y in years],\n",
    "    dim=\"month\")\n",
    "\n",
    "# admin1\n",
    "for i, row in enumerate(admin1_shp.itertuples()):\n",
    "    if i>1:\n",
    "        break\n",
    "    print(row.admin1)\n",
    "    mask = rasterize([(row.geometry, 1)],\n",
    "                        out_shape=pixel_statistic_stacked.shape[-2:],\n",
    "                        transform=pixel_statistic_stacked.rio.transform(),\n",
    "                        fill=0,\n",
    "                        all_touched=True,\n",
    "                        dtype=\"uint8\"\n",
    "                        ).astype(bool)\n",
    "    statistic_values = np.where(mask, pixel_statistic_stacked.values, np.nan)\n",
    "    print(statistic_values.shape)\n",
    "    pop_values = np.where(mask, pop_crop_alignment.values, np.nan)\n",
    "    pop_values_b = np.broadcast_to(pop_values, statistic_values.shape)\n",
    "    \n",
    "    unweighted_mean_per_month = np.nanmean(statistic_values, axis=(1,2))\n",
    "\n",
    "    valid = (~np.isnan(statistic_values)) & (~np.isnan(pop_values_b))\n",
    "    weighted_sum = np.nansum(statistic_values * pop_values_b * valid, axis=(1,2))\n",
    "    pop_sum = np.nansum(pop_values_b * valid, axis=(1,2))\n",
    "    \n",
    "    pop_weighted_mean_per_month = weighted_sum / pop_sum\n",
    "\n",
    "    for i in range(0, statistic_values.shape[0]):\n",
    "        stat_name = stat_names[i//(len(years)*12)]\n",
    "        year = (i - (i//(len(years)*12))*(len(years)*12)) // 12 + 2015\n",
    "        month = (i % 12) + 1\n",
    "        key = (row.admin1, year, month)\n",
    "        if key not in f_admin1_dict:\n",
    "            f_admin1_dict[key] = {\n",
    "                \"admin1\": row.admin1,\n",
    "                \"year\": year,\n",
    "                \"month\": month\n",
    "            }\n",
    "        f_admin1_dict[key][f\"{stat_name}_unweighted\"] = unweighted_mean_per_month[i]\n",
    "        f_admin1_dict[key][f\"{stat_name}_pop_weighted\"] = pop_weighted_mean_per_month[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1a04095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACEH\n",
      "(2, 2, 12, 2094, 5565)\n",
      "BALI\n",
      "(2, 2, 12, 2094, 5565)\n"
     ]
    }
   ],
   "source": [
    "f_admin1_dict = {}\n",
    "f_admin2_dict = {}\n",
    "\n",
    "# concatenate datasets\n",
    "pixel_statistic_stacked = xr.concat(\n",
    "    [\n",
    "        xr.concat(\n",
    "            [pixel_monthly_statistics_aligned[s][y] for y in years],\n",
    "            dim=\"year\"\n",
    "        ).assign_coords(year=years)\n",
    "        for s in stat_names[:2]\n",
    "    ],\n",
    "    dim=\"stat\"\n",
    ").assign_coords(stat=stat_names[:2])\n",
    "\n",
    "# admin1\n",
    "for i, row in enumerate(admin1_shp.itertuples()):\n",
    "    if i>1:\n",
    "        break\n",
    "    print(row.admin1)\n",
    "    mask = rasterize([(row.geometry, 1)],\n",
    "                        out_shape=pixel_statistic_stacked.shape[-2:],\n",
    "                        transform=pixel_statistic_stacked.rio.transform(),\n",
    "                        fill=0,\n",
    "                        all_touched=True,\n",
    "                        dtype=\"uint8\"\n",
    "                        ).astype(bool)\n",
    "    statistic_values = np.where(mask, pixel_statistic_stacked.values, np.nan)\n",
    "    print(statistic_values.shape)\n",
    "    pop_values = np.where(mask, pop_crop_alignment.values, np.nan)\n",
    "    pop_values_b = np.broadcast_to(pop_values, statistic_values.shape)\n",
    "    \n",
    "    unweighted_mean_per_month = np.nanmean(statistic_values, axis=(3,4))\n",
    "\n",
    "    valid = (~np.isnan(statistic_values)) & (~np.isnan(pop_values_b))\n",
    "    weighted_sum = np.nansum(statistic_values * pop_values_b * valid, axis=(3,4))\n",
    "    pop_sum = np.nansum(pop_values_b * valid, axis=(3,4))\n",
    "    \n",
    "    pop_weighted_mean_per_month = weighted_sum / pop_sum\n",
    "    for stat_i in range(statistic_values.shape[0]):\n",
    "        stat_name = stat_names[stat_i]\n",
    "        for year in range(2015, statistic_values.shape[1]+2015):\n",
    "            for month in range(1, statistic_values.shape[2]+1):\n",
    "                key = (row.admin1, year, month)\n",
    "                if key not in f_admin1_dict:\n",
    "                    f_admin1_dict[key] = {\n",
    "                        \"admin1\": row.admin1,\n",
    "                        \"year\": year,\n",
    "                        \"month\": month\n",
    "                    }\n",
    "                f_admin1_dict[key][f\"{stat_name}_unweighted\"] = unweighted_mean_per_month[stat_i, year-2015, month-1]\n",
    "                f_admin1_dict[key][f\"{stat_name}_pop_weighted\"] = pop_weighted_mean_per_month[stat_i, year-2015, month-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5845ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACEH\n"
     ]
    }
   ],
   "source": [
    "f_admin1_dict = {}\n",
    "f_admin2_dict = {}\n",
    "\n",
    "# concatenate datasets\n",
    "years = range(2015, 2025)\n",
    "pixel_statistic_stacked = xr.concat(\n",
    "    [\n",
    "        xr.concat(\n",
    "            [pixel_monthly_statistics_aligned[s][y] for y in years],\n",
    "            dim=\"year\"\n",
    "        ).assign_coords(year=years)\n",
    "        for s in stat_names[:]\n",
    "    ],\n",
    "    dim=\"stat\"\n",
    ").assign_coords(stat=stat_names[:])\n",
    "\n",
    "# admin1\n",
    "for i, row in enumerate(admin1_shp.itertuples()):\n",
    "    print(row.admin1)\n",
    "    mask = rasterize([(row.geometry, 1)],\n",
    "                        out_shape=pixel_statistic_stacked.shape[-2:],\n",
    "                        transform=pixel_statistic_stacked.rio.transform(),\n",
    "                        fill=0,\n",
    "                        all_touched=True,\n",
    "                        dtype=\"uint8\"\n",
    "                        ).astype(bool)\n",
    "    mask_da = xr.DataArray(\n",
    "        mask,\n",
    "        dims=(\"y\", \"x\"),\n",
    "        coords=pixel_statistic_stacked.isel(stat=0, year=0, month=0).coords\n",
    "    )\n",
    "\n",
    "    stat_m = pixel_statistic_stacked.where(mask_da)\n",
    "    pop_m = pop_crop_alignment.where(mask_da)\n",
    "\n",
    "    # ---- vectorised across stat, year, month ----\n",
    "    unweighted = stat_m.mean(dim=(\"y\", \"x\"))\n",
    "    weighted = (stat_m * pop_m).sum(dim=(\"y\", \"x\")) / pop_m.sum(dim=(\"y\", \"x\"))\n",
    "\n",
    "    # ---- write results ----\n",
    "    for stat in stat_m.stat.values:\n",
    "        for year in stat_m.year.values:\n",
    "            for month in stat_m.month.values:\n",
    "                key = (row.admin1, int(year), int(month))\n",
    "\n",
    "                d = f_admin1_dict.setdefault(\n",
    "                    key,\n",
    "                    {\"admin1\": row.admin1, \"year\": int(year), \"month\": int(month)}\n",
    "                )\n",
    "\n",
    "                d[f\"{stat}_unweighted\"] = float(unweighted.sel(stat=stat, year=year, month=month))\n",
    "                d[f\"{stat}_pop_weighted\"] = float(weighted.sel(stat=stat, year=year, month=month))\n",
    "# admin2\n",
    "for i, row in enumerate(admin2_shp.itertuples()):\n",
    "    print(row.admin2)\n",
    "    mask = rasterize([(row.geometry, 1)],\n",
    "                        out_shape=pixel_statistic_stacked.shape[-2:],\n",
    "                        transform=pixel_statistic_stacked.rio.transform(),\n",
    "                        fill=0,\n",
    "                        all_touched=True,\n",
    "                        dtype=\"uint8\"\n",
    "                        ).astype(bool)\n",
    "    mask_da = xr.DataArray(\n",
    "        mask,\n",
    "        dims=(\"y\", \"x\"),\n",
    "        coords=pixel_statistic_stacked.isel(stat=0, year=0, month=0).coords\n",
    "    )\n",
    "\n",
    "    stat_m = pixel_statistic_stacked.where(mask_da)\n",
    "    pop_m = pop_crop_alignment.where(mask_da)\n",
    "\n",
    "    # ---- vectorised across stat, year, month ----\n",
    "    unweighted = stat_m.mean(dim=(\"y\", \"x\"))\n",
    "    weighted = (stat_m * pop_m).sum(dim=(\"y\", \"x\")) / pop_m.sum(dim=(\"y\", \"x\"))\n",
    "\n",
    "    # ---- write results ----\n",
    "    for stat in stat_m.stat.values:\n",
    "        for year in stat_m.year.values:\n",
    "            for month in stat_m.month.values:\n",
    "                key = (row.admin2, int(year), int(month))\n",
    "\n",
    "                d = f_admin2_dict.setdefault(\n",
    "                    key,\n",
    "                    {\"admin2\": row.admin2, \"year\": int(year), \"month\": int(month)}\n",
    "                )\n",
    "\n",
    "                d[f\"{stat}_unweighted\"] = float(unweighted.sel(stat=stat, year=year, month=month))\n",
    "                d[f\"{stat}_pop_weighted\"] = float(weighted.sel(stat=stat, year=year, month=month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "f_admin1_records = list(f_admin1_dict.values())\n",
    "f_df_admin1_statistics = pd.DataFrame(f_admin1_records)\n",
    "f_df_admin1_statistics = f_df_admin1_statistics.sort_values(by=[\"admin1\", \"year\", \"month\"]).reset_index(drop=True)\n",
    "\n",
    "f_admin2_records = list(f_admin2_dict.values())\n",
    "f_df_admin2_statistics = pd.DataFrame(f_admin2_records)\n",
    "f_df_admin2_statistics = f_df_admin2_statistics.sort_values(by=[\"admin2\", \"year\", \"month\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d95a969a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 7)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df_admin1_statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0455a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admin1', 'year', 'month', 't2m_mean_unweighted',\n",
       "       't2m_mean_pop_weighted', 't2m_min_unweighted', 't2m_min_pop_weighted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df_admin1_statistics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d26e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admin1', 'year', 'month', 't2m_mean_unweighted',\n",
       "       't2m_mean_pop_weighted', 't2m_min_unweighted', 't2m_min_pop_weighted',\n",
       "       't2m_max_unweighted', 't2m_max_pop_weighted', 'tp_mean_unweighted',\n",
       "       'tp_mean_pop_weighted', 'rh_mean_unweighted', 'rh_mean_pop_weighted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_admin1_statistics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1de528bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(f_df_admin2_statistics == df_admin2_statistics[['admin2', 'year', 'month', 't2m_mean_unweighted',\n",
    "       't2m_mean_pop_weighted', 't2m_min_unweighted', 't2m_min_pop_weighted']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5d4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p-phylo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
